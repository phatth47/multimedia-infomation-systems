{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015079,
     "end_time": "2024-02-22T02:41:48.970163",
     "exception": false,
     "start_time": "2024-02-22T02:41:48.955084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "This kernel is a simple example of fruit classification with a simple CNN implemented with Keras model and tools. Click the blue \"Edit Notebook\" or \"Fork Notebook\" button at the top of this kernel to begin editing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014125,
     "end_time": "2024-02-22T02:41:48.999627",
     "exception": false,
     "start_time": "2024-02-22T02:41:48.985502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## General Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 14:42:30.718788: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/tranphat/PycharmProjects/fruit/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T07:42:35.211880Z",
     "start_time": "2024-02-24T07:42:27.607477Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2024-02-22T02:41:49.032970Z",
     "iopub.status.busy": "2024-02-22T02:41:49.032259Z",
     "iopub.status.idle": "2024-02-22T02:41:55.077850Z",
     "shell.execute_reply": "2024-02-22T02:41:55.078285Z",
     "shell.execute_reply.started": "2024-02-22T02:33:46.354643Z"
    },
    "papermill": {
     "duration": 6.064162,
     "end_time": "2024-02-22T02:41:55.078452",
     "exception": false,
     "start_time": "2024-02-22T02:41:49.014290",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:37:20.875037Z",
     "start_time": "2024-02-24T07:37:20.829506Z"
    }
   },
   "outputs": [],
   "source": [
    "# General Libs\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014147,
     "end_time": "2024-02-22T02:41:55.107182",
     "exception": false,
     "start_time": "2024-02-22T02:41:55.093035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Exploratory Analysis\n",
    "Let's view some dataset samples.\n",
    "\n",
    "This example uses keras ImageDataGenerator. This lib turns easier to read and use image classes from a subdirectoty structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013837,
     "end_time": "2024-02-22T02:41:55.135358",
     "exception": false,
     "start_time": "2024-02-22T02:41:55.121521",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:42:35.218241Z",
     "start_time": "2024-02-24T07:42:35.214Z"
    }
   },
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2024-02-22T02:41:55.168829Z",
     "iopub.status.busy": "2024-02-22T02:41:55.168177Z",
     "iopub.status.idle": "2024-02-22T02:41:55.172598Z",
     "shell.execute_reply": "2024-02-22T02:41:55.173077Z",
     "shell.execute_reply.started": "2024-02-22T02:33:51.454393Z"
    },
    "papermill": {
     "duration": 0.022808,
     "end_time": "2024-02-22T02:41:55.173269",
     "exception": false,
     "start_time": "2024-02-22T02:41:55.150461",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:42:35.225733Z",
     "start_time": "2024-02-24T07:42:35.216864Z"
    }
   },
   "outputs": [],
   "source": [
    "im_shape = (250,250)\n",
    "\n",
    "TRAINING_DIR = './dataset/fruits-360/Training'\n",
    "TEST_DIR = './dataset/fruits-360/Test'\n",
    "\n",
    "seed = 10\n",
    "\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:41:55.206693Z",
     "iopub.status.busy": "2024-02-22T02:41:55.205875Z",
     "iopub.status.idle": "2024-02-22T02:41:55.210082Z",
     "shell.execute_reply": "2024-02-22T02:41:55.210649Z",
     "shell.execute_reply.started": "2024-02-22T02:33:51.459734Z"
    },
    "papermill": {
     "duration": 0.022554,
     "end_time": "2024-02-22T02:41:55.210797",
     "exception": false,
     "start_time": "2024-02-22T02:41:55.188243",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:42:35.233007Z",
     "start_time": "2024-02-24T07:42:35.227813Z"
    }
   },
   "outputs": [],
   "source": [
    "#Using keras ImageGenerator and flow_from_directoty\n",
    "\n",
    "# Subdivision in test/validation\n",
    "data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "val_data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:41:55.243459Z",
     "iopub.status.busy": "2024-02-22T02:41:55.242810Z",
     "iopub.status.idle": "2024-02-22T02:41:55.249551Z",
     "shell.execute_reply": "2024-02-22T02:41:55.248977Z",
     "shell.execute_reply.started": "2024-02-22T02:33:51.479548Z"
    },
    "papermill": {
     "duration": 0.024308,
     "end_time": "2024-02-22T02:41:55.249666",
     "exception": false,
     "start_time": "2024-02-22T02:41:55.225358",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:42:39.857006Z",
     "start_time": "2024-02-24T07:42:35.235442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54190 images belonging to 131 classes.\n",
      "Found 13502 images belonging to 131 classes.\n",
      "Found 22688 images belonging to 131 classes.\n",
      "Classes: ['Apple Braeburn', 'Apple Crimson Snow', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3', 'Apple Granny Smith', 'Apple Pink Lady', 'Apple Red 1', 'Apple Red 2', 'Apple Red 3', 'Apple Red Delicious', 'Apple Red Yellow 1', 'Apple Red Yellow 2', 'Apricot', 'Avocado', 'Avocado ripe', 'Banana', 'Banana Lady Finger', 'Banana Red', 'Beetroot', 'Blueberry', 'Cactus fruit', 'Cantaloupe 1', 'Cantaloupe 2', 'Carambula', 'Cauliflower', 'Cherry 1', 'Cherry 2', 'Cherry Rainier', 'Cherry Wax Black', 'Cherry Wax Red', 'Cherry Wax Yellow', 'Chestnut', 'Clementine', 'Cocos', 'Corn', 'Corn Husk', 'Cucumber Ripe', 'Cucumber Ripe 2', 'Dates', 'Eggplant', 'Fig', 'Ginger Root', 'Granadilla', 'Grape Blue', 'Grape Pink', 'Grape White', 'Grape White 2', 'Grape White 3', 'Grape White 4', 'Grapefruit Pink', 'Grapefruit White', 'Guava', 'Hazelnut', 'Huckleberry', 'Kaki', 'Kiwi', 'Kohlrabi', 'Kumquats', 'Lemon', 'Lemon Meyer', 'Limes', 'Lychee', 'Mandarine', 'Mango', 'Mango Red', 'Mangostan', 'Maracuja', 'Melon Piel de Sapo', 'Mulberry', 'Nectarine', 'Nectarine Flat', 'Nut Forest', 'Nut Pecan', 'Onion Red', 'Onion Red Peeled', 'Onion White', 'Orange', 'Papaya', 'Passion Fruit', 'Peach', 'Peach 2', 'Peach Flat', 'Pear', 'Pear 2', 'Pear Abate', 'Pear Forelle', 'Pear Kaiser', 'Pear Monster', 'Pear Red', 'Pear Stone', 'Pear Williams', 'Pepino', 'Pepper Green', 'Pepper Orange', 'Pepper Red', 'Pepper Yellow', 'Physalis', 'Physalis with Husk', 'Pineapple', 'Pineapple Mini', 'Pitahaya Red', 'Plum', 'Plum 2', 'Plum 3', 'Pomegranate', 'Pomelo Sweetie', 'Potato Red', 'Potato Red Washed', 'Potato Sweet', 'Potato White', 'Quince', 'Rambutan', 'Raspberry', 'Redcurrant', 'Salak', 'Strawberry', 'Strawberry Wedge', 'Tamarillo', 'Tangelo', 'Tomato 1', 'Tomato 2', 'Tomato 3', 'Tomato 4', 'Tomato Cherry Red', 'Tomato Heart', 'Tomato Maroon', 'Tomato Yellow', 'Tomato not Ripened', 'Walnut', 'Watermelon']\n"
     ]
    }
   ],
   "source": [
    "# If you want data augmentation, uncomment and run this cell\n",
    "data_generator = ImageDataGenerator(\n",
    "        validation_split=0.2,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "val_data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-02-22T02:41:55.286542Z",
     "iopub.status.busy": "2024-02-22T02:41:55.285881Z",
     "iopub.status.idle": "2024-02-22T02:41:55.639576Z",
     "shell.execute_reply": "2024-02-22T02:41:55.639030Z",
     "shell.execute_reply.started": "2024-02-22T02:33:51.492957Z"
    },
    "papermill": {
     "duration": 0.375639,
     "end_time": "2024-02-22T02:41:55.639676",
     "exception": false,
     "start_time": "2024-02-22T02:41:55.264037",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:37:25.688567Z",
     "start_time": "2024-02-24T07:37:20.917455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54190 images belonging to 131 classes.\n",
      "Found 13502 images belonging to 131 classes.\n",
      "Found 22688 images belonging to 131 classes.\n",
      "Classes: ['Apple Braeburn', 'Apple Crimson Snow', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3', 'Apple Granny Smith', 'Apple Pink Lady', 'Apple Red 1', 'Apple Red 2', 'Apple Red 3', 'Apple Red Delicious', 'Apple Red Yellow 1', 'Apple Red Yellow 2', 'Apricot', 'Avocado', 'Avocado ripe', 'Banana', 'Banana Lady Finger', 'Banana Red', 'Beetroot', 'Blueberry', 'Cactus fruit', 'Cantaloupe 1', 'Cantaloupe 2', 'Carambula', 'Cauliflower', 'Cherry 1', 'Cherry 2', 'Cherry Rainier', 'Cherry Wax Black', 'Cherry Wax Red', 'Cherry Wax Yellow', 'Chestnut', 'Clementine', 'Cocos', 'Corn', 'Corn Husk', 'Cucumber Ripe', 'Cucumber Ripe 2', 'Dates', 'Eggplant', 'Fig', 'Ginger Root', 'Granadilla', 'Grape Blue', 'Grape Pink', 'Grape White', 'Grape White 2', 'Grape White 3', 'Grape White 4', 'Grapefruit Pink', 'Grapefruit White', 'Guava', 'Hazelnut', 'Huckleberry', 'Kaki', 'Kiwi', 'Kohlrabi', 'Kumquats', 'Lemon', 'Lemon Meyer', 'Limes', 'Lychee', 'Mandarine', 'Mango', 'Mango Red', 'Mangostan', 'Maracuja', 'Melon Piel de Sapo', 'Mulberry', 'Nectarine', 'Nectarine Flat', 'Nut Forest', 'Nut Pecan', 'Onion Red', 'Onion Red Peeled', 'Onion White', 'Orange', 'Papaya', 'Passion Fruit', 'Peach', 'Peach 2', 'Peach Flat', 'Pear', 'Pear 2', 'Pear Abate', 'Pear Forelle', 'Pear Kaiser', 'Pear Monster', 'Pear Red', 'Pear Stone', 'Pear Williams', 'Pepino', 'Pepper Green', 'Pepper Orange', 'Pepper Red', 'Pepper Yellow', 'Physalis', 'Physalis with Husk', 'Pineapple', 'Pineapple Mini', 'Pitahaya Red', 'Plum', 'Plum 2', 'Plum 3', 'Pomegranate', 'Pomelo Sweetie', 'Potato Red', 'Potato Red Washed', 'Potato Sweet', 'Potato White', 'Quince', 'Rambutan', 'Raspberry', 'Redcurrant', 'Salak', 'Strawberry', 'Strawberry Wedge', 'Tamarillo', 'Tangelo', 'Tomato 1', 'Tomato 2', 'Tomato 3', 'Tomato 4', 'Tomato Cherry Red', 'Tomato Heart', 'Tomato Maroon', 'Tomato Yellow', 'Tomato not Ripened', 'Walnut', 'Watermelon']\n"
     ]
    }
   ],
   "source": [
    "# Generator para parte train\n",
    "train_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=True, seed=seed,\n",
    "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n",
    "# Generator para parte validação\n",
    "validation_generator = val_data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=False, seed=seed,\n",
    "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n",
    "\n",
    "# Generator para dataset de teste\n",
    "test_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_generator.flow_from_directory(TEST_DIR, target_size=im_shape, shuffle=False, seed=seed,\n",
    "                                                     class_mode='categorical', batch_size=BATCH_SIZE)\n",
    "\n",
    "nb_train_samples = train_generator.samples\n",
    "nb_validation_samples = validation_generator.samples\n",
    "nb_test_samples = test_generator.samples\n",
    "classes = list(train_generator.class_indices.keys())\n",
    "print('Classes: '+str(classes))\n",
    "num_classes  = len(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014726,
     "end_time": "2024-02-22T02:41:55.670192",
     "exception": false,
     "start_time": "2024-02-22T02:41:55.655466",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:42:43.324943Z",
     "start_time": "2024-02-24T07:42:39.870725Z"
    }
   },
   "source": [
    "### Showing some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-02-22T02:41:55.708638Z",
     "iopub.status.busy": "2024-02-22T02:41:55.707965Z",
     "iopub.status.idle": "2024-02-22T02:41:59.200604Z",
     "shell.execute_reply": "2024-02-22T02:41:59.201049Z",
     "shell.execute_reply.started": "2024-02-22T02:33:51.838999Z"
    },
    "papermill": {
     "duration": 3.515826,
     "end_time": "2024-02-22T02:41:59.201208",
     "exception": false,
     "start_time": "2024-02-22T02:41:55.685382",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:37:26.044807Z",
     "start_time": "2024-02-24T07:37:25.694179Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m9\u001B[39m):\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m#gera subfigures\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     plt\u001B[38;5;241m.\u001B[39msubplot(\u001B[38;5;241m330\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m i)\n\u001B[0;32m----> 6\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m255\u001B[39m\n\u001B[1;32m      7\u001B[0m     image \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muint8\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      8\u001B[0m     plt\u001B[38;5;241m.\u001B[39mimshow(image)\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/keras/src/preprocessing/image.py:168\u001B[0m, in \u001B[0;36mIterator.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    165\u001B[0m     index_array \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex_generator)\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m# The transformation of images is not under thread lock\u001B[39;00m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;66;03m# so it can be done in parallel\u001B[39;00m\n\u001B[0;32m--> 168\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_batches_of_transformed_samples\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex_array\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/keras/src/preprocessing/image.py:370\u001B[0m, in \u001B[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001B[0;34m(self, index_array)\u001B[0m\n\u001B[1;32m    368\u001B[0m filepaths \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilepaths\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(index_array):\n\u001B[0;32m--> 370\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mimage_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_img\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    371\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilepaths\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    372\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolor_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolor_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    373\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    375\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_aspect_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeep_aspect_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    376\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m     x \u001B[38;5;241m=\u001B[39m image_utils\u001B[38;5;241m.\u001B[39mimg_to_array(img, data_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_format)\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;66;03m# Pillow images should be closed after `load_img`,\u001B[39;00m\n\u001B[1;32m    379\u001B[0m     \u001B[38;5;66;03m# but not PIL images.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/keras/src/utils/image_utils.py:414\u001B[0m, in \u001B[0;36mload_img\u001B[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001B[0m\n\u001B[1;32m    412\u001B[0m     color_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrayscale\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pil_image \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 414\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m    415\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not import PIL.Image. The use of `load_img` requires PIL.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    416\u001B[0m     )\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, io\u001B[38;5;241m.\u001B[39mBytesIO):\n\u001B[1;32m    418\u001B[0m     img \u001B[38;5;241m=\u001B[39m pil_image\u001B[38;5;241m.\u001B[39mopen(path)\n",
      "\u001B[0;31mImportError\u001B[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1500x1500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing some examples\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(9):\n",
    "    #gera subfigures\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    batch = train_generator.next()[0]*255\n",
    "    image = batch[0].astype('uint8')\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032251,
     "end_time": "2024-02-22T02:41:59.268641",
     "exception": false,
     "start_time": "2024-02-22T02:41:59.236390",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:42:43.842517Z",
     "start_time": "2024-02-24T07:42:43.324558Z"
    }
   },
   "source": [
    "## Creating a simple CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-02-22T02:41:59.336262Z",
     "iopub.status.busy": "2024-02-22T02:41:59.335573Z",
     "iopub.status.idle": "2024-02-22T02:41:59.792826Z",
     "shell.execute_reply": "2024-02-22T02:41:59.792298Z",
     "shell.execute_reply.started": "2024-02-22T02:33:54.893948Z"
    },
    "papermill": {
     "duration": 0.492323,
     "end_time": "2024-02-22T02:41:59.792961",
     "exception": false,
     "start_time": "2024-02-22T02:41:59.300638",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:43:35.569291Z",
     "start_time": "2024-02-24T07:42:43.848302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "  57/3386 [..............................] - ETA: 46:42 - loss: 8.3110 - accuracy: 0.0186"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 12\u001B[0m\n\u001B[1;32m      4\u001B[0m callbacks_list \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      5\u001B[0m     keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mModelCheckpoint(\n\u001B[1;32m      6\u001B[0m         filepath\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel.h5\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      7\u001B[0m         monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m),\n\u001B[1;32m      8\u001B[0m     keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      9\u001B[0m ]\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m#Training\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnb_train_samples\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcallbacks_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnb_validation_samples\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/keras/src/engine/training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1805\u001B[0m ):\n\u001B[1;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    867\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 868\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    874\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m     args,\n\u001B[1;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1327\u001B[0m     executing_eagerly)\n\u001B[1;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1501\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/fruit/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(20, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(im_shape[0],im_shape[1],3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(40, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Compila o modelo\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:41:59.864635Z",
     "iopub.status.busy": "2024-02-22T02:41:59.863955Z",
     "iopub.status.idle": "2024-02-22T02:44:53.523462Z",
     "shell.execute_reply": "2024-02-22T02:44:53.523926Z",
     "shell.execute_reply.started": "2024-02-22T02:33:55.333112Z"
    },
    "papermill": {
     "duration": 173.698647,
     "end_time": "2024-02-22T02:44:53.524089",
     "exception": false,
     "start_time": "2024-02-22T02:41:59.825442",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-24T07:43:35.575687Z",
     "start_time": "2024-02-24T07:43:35.573377Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "\n",
    "#Callback to save the best model\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='model.h5',\n",
    "        monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n",
    "]\n",
    "\n",
    "#Training\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // BATCH_SIZE,\n",
    "        epochs=epochs,\n",
    "        callbacks = callbacks_list,\n",
    "        validation_data=validation_generator,\n",
    "        verbose = 1,\n",
    "        validation_steps=nb_validation_samples // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:44:53.802080Z",
     "iopub.status.busy": "2024-02-22T02:44:53.801292Z",
     "iopub.status.idle": "2024-02-22T02:44:54.077092Z",
     "shell.execute_reply": "2024-02-22T02:44:54.077550Z",
     "shell.execute_reply.started": "2024-02-22T02:37:15.040308Z"
    },
    "papermill": {
     "duration": 0.417398,
     "end_time": "2024-02-22T02:44:54.077682",
     "exception": false,
     "start_time": "2024-02-22T02:44:53.660284",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:37:26.051608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs_x = range(1, len(loss_values) + 1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(epochs_x, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation Loss and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs_x, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n",
    "#plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.131188,
     "end_time": "2024-02-22T02:44:54.341472",
     "exception": false,
     "start_time": "2024-02-22T02:44:54.210284",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:43:35.576756Z"
    }
   },
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:44:54.607775Z",
     "iopub.status.busy": "2024-02-22T02:44:54.607107Z",
     "iopub.status.idle": "2024-02-22T02:44:55.537269Z",
     "shell.execute_reply": "2024-02-22T02:44:55.537755Z",
     "shell.execute_reply.started": "2024-02-22T02:37:15.331543Z"
    },
    "papermill": {
     "duration": 1.064626,
     "end_time": "2024-02-22T02:44:55.537916",
     "exception": false,
     "start_time": "2024-02-22T02:44:54.473290",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:43:35.579972Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the best saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:44:55.803709Z",
     "iopub.status.busy": "2024-02-22T02:44:55.802703Z",
     "iopub.status.idle": "2024-02-22T02:44:56.201696Z",
     "shell.execute_reply": "2024-02-22T02:44:56.201057Z",
     "shell.execute_reply.started": "2024-02-22T02:37:16.470520Z"
    },
    "papermill": {
     "duration": 0.532409,
     "end_time": "2024-02-22T02:44:56.201807",
     "exception": false,
     "start_time": "2024-02-22T02:44:55.669398",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:43:35.582990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using the validation dataset\n",
    "score = model.evaluate_generator(validation_generator)\n",
    "print('Val loss:', score[0])\n",
    "print('Val accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:44:56.473078Z",
     "iopub.status.busy": "2024-02-22T02:44:56.472520Z",
     "iopub.status.idle": "2024-02-22T02:44:56.947870Z",
     "shell.execute_reply": "2024-02-22T02:44:56.947201Z",
     "shell.execute_reply.started": "2024-02-22T02:37:16.855523Z"
    },
    "papermill": {
     "duration": 0.611278,
     "end_time": "2024-02-22T02:44:56.947983",
     "exception": false,
     "start_time": "2024-02-22T02:44:56.336705",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:43:35.585939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using the test dataset\n",
    "score = model.evaluate_generator(test_generator)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:44:57.222335Z",
     "iopub.status.busy": "2024-02-22T02:44:57.214365Z",
     "iopub.status.idle": "2024-02-22T02:44:57.223875Z",
     "shell.execute_reply": "2024-02-22T02:44:57.224367Z",
     "shell.execute_reply.started": "2024-02-22T02:37:17.279557Z"
    },
    "papermill": {
     "duration": 0.145156,
     "end_time": "2024-02-22T02:44:57.224507",
     "exception": false,
     "start_time": "2024-02-22T02:44:57.079351",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:43:35.588412Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "#Plot the confusion matrix. Set Normalize = True/False\n",
    "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:44:57.491149Z",
     "iopub.status.busy": "2024-02-22T02:44:57.490621Z",
     "iopub.status.idle": "2024-02-22T02:44:58.916383Z",
     "shell.execute_reply": "2024-02-22T02:44:58.915710Z",
     "shell.execute_reply.started": "2024-02-22T02:37:17.294613Z"
    },
    "papermill": {
     "duration": 1.559877,
     "end_time": "2024-02-22T02:44:58.916500",
     "exception": false,
     "start_time": "2024-02-22T02:44:57.356623",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:43:35.590713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some reports\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "#On test dataset\n",
    "Y_pred = model.predict_generator(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "target_names = classes\n",
    "\n",
    "#Confution Matrix\n",
    "cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "plot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n",
    "\n",
    "#Classification Report\n",
    "print('Classification Report')\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:44:59.189330Z",
     "iopub.status.busy": "2024-02-22T02:44:59.188761Z",
     "iopub.status.idle": "2024-02-22T02:44:59.197832Z",
     "shell.execute_reply": "2024-02-22T02:44:59.198414Z",
     "shell.execute_reply.started": "2024-02-22T02:37:18.600837Z"
    },
    "papermill": {
     "duration": 0.147076,
     "end_time": "2024-02-22T02:44:59.198577",
     "exception": false,
     "start_time": "2024-02-22T02:44:59.051501",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:43:35.594350Z"
    }
   },
   "outputs": [],
   "source": [
    "model_feature = Model(inputs=model.input, outputs=model.get_layer(index=3).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:44:59.469317Z",
     "iopub.status.busy": "2024-02-22T02:44:59.468747Z",
     "iopub.status.idle": "2024-02-22T02:44:59.621834Z",
     "shell.execute_reply": "2024-02-22T02:44:59.622383Z",
     "shell.execute_reply.started": "2024-02-22T02:39:15.674338Z"
    },
    "papermill": {
     "duration": 0.28903,
     "end_time": "2024-02-22T02:44:59.622549",
     "exception": false,
     "start_time": "2024-02-22T02:44:59.333519",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:43:35.596653Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Đường dẫn tới hình ảnh\n",
    "img_path = '../input/ds_frutas_am/train/acai/images (1).jpeg'\n",
    "\n",
    "# Đọc và xử lý hình ảnh\n",
    "img = image.load_img(img_path, target_size=(im_shape[0], im_shape[1]))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "X = img_array_expanded_dims / 255.0  # Chuẩn hóa nếu cần\n",
    "\n",
    "# Bây giờ, X đã sẵn sàng để được dùng trong model_feature.predict(X)\n",
    "\n",
    "features = model_feature.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:44:59.890435Z",
     "iopub.status.busy": "2024-02-22T02:44:59.889779Z",
     "iopub.status.idle": "2024-02-22T02:44:59.893635Z",
     "shell.execute_reply": "2024-02-22T02:44:59.894026Z",
     "shell.execute_reply.started": "2024-02-22T02:39:22.216995Z"
    },
    "papermill": {
     "duration": 0.140003,
     "end_time": "2024-02-22T02:44:59.894178",
     "exception": false,
     "start_time": "2024-02-22T02:44:59.754175",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:43:35.598788Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('features.npy', features)  # Lưu vector đặc trưng vào tệp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T02:45:00.163261Z",
     "iopub.status.busy": "2024-02-22T02:45:00.162716Z",
     "iopub.status.idle": "2024-02-22T02:45:00.167556Z",
     "shell.execute_reply": "2024-02-22T02:45:00.168079Z",
     "shell.execute_reply.started": "2024-02-22T02:41:14.629174Z"
    },
    "papermill": {
     "duration": 0.14018,
     "end_time": "2024-02-22T02:45:00.168258",
     "exception": false,
     "start_time": "2024-02-22T02:45:00.028078",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-24T07:37:26.076530Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('features.npy')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 958196,
     "sourceId": 1622250,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30038,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 195.991964,
   "end_time": "2024-02-22T02:45:00.510535",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-22T02:41:44.518571",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
